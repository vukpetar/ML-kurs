{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Opisivanje slike sa RNN\n",
    "U ovoj vježbi ćete implementirati vanila rekurentne neuralne mreže i iskoristiti ih da se trenira model koji generiše opise slika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from funkcije.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from funkcije.rnn_layers import *\n",
    "from funkcije.captioning_solver import CaptioningSolver\n",
    "from funkcije.classifiers.rnn import CaptioningRNN\n",
    "from funkcije.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from funkcije.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" vraća relativnu grešku \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instaliranje h5py\n",
    "COCO dataset će biti korišten koji se nalazi u HDF5 formatu. Da biste učitali HDF5 fajlove, potrebno je da instalirate `h5py` Python pakaet. Iz komandne linije, pokrenite:<br/>\n",
    "`pip install h5py`  <br/>\n",
    "Ako dobijete grešku u dozvoli, biće potrebno da komandu pokrenete kao root:<br/>\n",
    "```sudo pip install h5py```\n",
    "\n",
    "Takođe možete pokrenuti komandu direktno iz Jupyter notebook dodavši karakter \"!\" kao prefiks komandi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# Microsoft COCO\n",
    "Za ovu vježbu koristićete 2014 izdanje [Microsoft COCO dataset](http://mscoco.org/) koji je postao standard za testiranje opisivanja slika. Dataset se sastoji od 80 000 trening slika i 40000 validacionih slika, svakoj pribilježeno 5 titlova koji su napisani od strane radnika na Amazon Mechanical Turk.\n",
    "\n",
    "Trebalo je da ste već skinuli podatke u direktorijumu `funkcije/datasets` i pokrenuti skriptu `get_assignment3_data.sh`. Ako do sada niste to uradili, sada pokrenite skriptu. Napomena: COCO podaci su ~1GB.\n",
    "\n",
    "Mi smo obradili podatke i izvukli karakteristike za vas. \n",
    "\n",
    "Sirove slike zauzimaju previše prostora (blizu 20GB) tako da ih nismo uključili u skidanje. Međutim sve slike su uzete sa Flickr, i URL-ovi trening i validacionih slika su smješteni u fajlovima `train2014_urls.txt` i `val2014_urls.txt` respektivno. Ovo vam dozvoljava da skinete slike u hodu za vizuelizaciju. Kako su slike skinute u hodu, **morate biti konektovani na internetu da biste vidjeli slike**.\n",
    "\n",
    "Bavljenje stringovima je neefikasno, pa ćemo raditi sa kodiranom verzijom opisa. Svakoj riječi je dodijeljen integer ID, dozvoljavajući nam da predstavimo opis kao sekvencu integers. Mapiranje između integers ID-ova i riječi je u fajlu `coco2014_vocab.json`, i možete koristiti funkciju `decode_captions` iz fajla `funkcije/coco_utils.py` da pretvorite numpx nizove ID-ova u stringove. \n",
    "\n",
    "Postoji par specijalnih tokena koje smo dodali u vokabularu. Na početku svakog opisa smo dodali `<START>` token i na kraju `<END>` token. Rijetke riječi su zamijenjene sa `<UNK>` tokenom (\"unknown\"). Kako želimo da treniramo minibatches koji sadrže opise različitih težina, proširujemo kratke opise sa `<NULL>` tokenom posle `<END>` tokena i ne računamo funkciju cilja ili gradijente za `<NULL>` tokene. S obzirom da specijalni tokeni mogu prouzrokavati dosta glavobolje, mi smo se pobrinuli o svim detaljima implementacije vezane za specijalne tokene.\n",
    "\n",
    "Možete učitati sve MS-COCo podatke (opise, karakteristike, URL-ove i vokabular) koristeći `load_coco_data` funkciju iz fajla `funkcije/coco_utils.py`. Pokrenite sledeću ćeliju:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Učitavanje COCO podataka sa diska; ovo vraća rečnik\n",
    "# Mi ćemo raditi sa dimenziono smanjenim karakteristikama, ali osjećajte \n",
    "# se slobodnim da eksperimentišete sa originalnim karakteristikama mijenjajući indikator ispod. \n",
    "\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Štampajte sve ključeve i vrijednosti iz rečnika podataka\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pogledajte podatke\n",
    "Uvijek je dobra ideja pogledati primjere iz dataset-a prije rada sa njima. \n",
    "\n",
    "Možete koristiti `sample_coco_minibatch` funkciju iz fajla `funkcije/coco_utils.py` da uzmete uzorke podataka iz strukture podataka iz `load_coco_data`. Pokrenite sledeću ćeliju da prikažete uzorak slika i njihovih opisa. Pokrećući ih više puta i gledajući rezultate će vam pomoći da steknete utisak o dataset-u.\n",
    "\n",
    "Primijetite da dekodiramo opise koristeći `decode_captions` funkciju i da skidamo slike u hodu koristeći Flickr URL, tako da **morate biti povezani na internetu da biste vidjeli  slike**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n",
    "for i, (caption, url) in enumerate(zip(captions, urls)):\n",
    "    plt.imshow(image_from_url(url))\n",
    "    plt.axis('off')\n",
    "    caption_str = decode_captions(caption, data['idx_to_word'])\n",
    "    plt.title(caption_str)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rekurentne Neuralne Mreže\n",
    "Koristićemo modele jezika rekurentnih neuralnih mreža za opisivanje slika. Fajl `funkcije/rnn_layers.py` sadrži implementacije različitih slojeva koji su potrebni za rekurentne neuralne mreže, a fajl `funkcije/classifiers/rnn.py` koristi te slojeve za implementaciju modela opisivanja slika. \n",
    "\n",
    "Prvo ćemo implementirati različite tipove RNN slojeva u `funkcije/rnn_layers.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanila RNN: korak unaprijed\n",
    "Otvorite fajl `funkcije/rnn_layers.py`. Ovaj fajl implementira prolaze unaprijed i unazad za različite tipove slojeva koji se često koriste u rekurentnim neuralnim mrežama.\n",
    "\n",
    "Prvo implementirajte funkciju `rnn_step_forward` koja implementira prolaz unaprijed za jedan vremenski korak vanila rekurentne neuralne mreže. Nakon toga pokrenite sledeću ćeliju da biste provjerili vašu implementaciju. Trebate da vidite grešku reda `e-8` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, H = 3, 10, 4\n",
    "\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.2, 0.4, num=H)\n",
    "\n",
    "next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "expected_next_h = np.asarray([\n",
    "  [-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "  [ 0.66854692,  0.79562378,  0.87755553,  0.92795967],\n",
    "  [ 0.97934501,  0.99144213,  0.99646691,  0.99854353]])\n",
    "\n",
    "print('next_h greška: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanila RNN: korak unazad\n",
    "U fajlu `funkcije/rnn_layers.py` implementirajte `rnn_step_backward` funkciju. Nakon toga pokrenite sledeću ćeliju da biste provjerili vašu implementaciju. Trebali biste da vidite grešku reda `e-8` ili manje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funkcije.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "np.random.seed(231)\n",
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "h = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_step_forward(x, h, Wx, Wh, b)\n",
    "\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "\n",
    "fx = lambda x: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fh = lambda prev_h: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dnext_h)\n",
    "dprev_h_num = eval_numerical_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dnext_h)\n",
    "\n",
    "dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)\n",
    "\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dprev_h greška: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx greška: ', rel_error(dWx_num, dWx))\n",
    "print('dWh greška: ', rel_error(dWh_num, dWh))\n",
    "print('db greška: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanila RNN: unaprijed\n",
    "Sada kada ste implementirali prolaze unaprijed i unazad za jedan vremenski korak vanila RNN, kombinovaćete te djelove da biste implementirali RNN koja prolazi kroz cijelu sekvencu podataka.\n",
    "\n",
    "U fajlu `funkcije/rnn_layers.py`, implementirajte funkciju `rnn_forward`. Ovo trebate implementirati koristeći `rnn_step_forward` funkciju koju ste definisali iznad. Nakon toga pokrenite sledeću ćeliju da biste provjerili vašu implementaciju. Trebali biste vidjeti grešku reda `e-7` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, D, H = 2, 3, 4, 5\n",
    "\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.7, 0.1, num=H)\n",
    "\n",
    "h, _ = rnn_forward(x, h0, Wx, Wh, b)\n",
    "expected_h = np.asarray([\n",
    "  [\n",
    "    [-0.42070749, -0.27279261, -0.11074945,  0.05740409,  0.22236251],\n",
    "    [-0.39525808, -0.22554661, -0.0409454,   0.14649412,  0.32397316],\n",
    "    [-0.42305111, -0.24223728, -0.04287027,  0.15997045,  0.35014525],\n",
    "  ],\n",
    "  [\n",
    "    [-0.55857474, -0.39065825, -0.19198182,  0.02378408,  0.23735671],\n",
    "    [-0.27150199, -0.07088804,  0.13562939,  0.33099728,  0.50158768],\n",
    "    [-0.51014825, -0.30524429, -0.06755202,  0.17806392,  0.40333043]]])\n",
    "print('h greška: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanila RNN: unazad\n",
    "U fajlu `funkcije/rnn_layers.py`, implementirajte prolaz unazad za vanila RNN u funkciji `rnn_backward`. Ovo treba pokrenuti  back-propagation nad cijelom sekvencom, pozivajući `rnn_step_backward` funkciju koju ste definisali ranije. Trebali biste vidjeti greške reda `e-6` ili manje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "\n",
    "out, cache = rnn_forward(x, h0, Wx, Wh, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)\n",
    "\n",
    "fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dh0 greška: ', rel_error(dh0_num, dh0))\n",
    "print('dWx greška: ', rel_error(dWx_num, dWx))\n",
    "print('dWh greška: ', rel_error(dWh_num, dWh))\n",
    "print('db greška: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding: unaprijed\n",
    "U sistemima dubokog učenja, često riječi predstavljamo vektorima. Svakoj riječi u vokabularu je pridružen vektor, i ovi vektori će se naučiti sa ostatkom sistema.\n",
    "\n",
    "U fajlu `funkcije/rnn_layers.py`, implementirajte funkciju `word_embedding_forward` da konvertujete riječi (predstavljene cijelim brojevima - integers)) u vektore. Pokrenite sledeću ćeliju da biste provjerili vašu implementaciju. Trebalo bi da vidite grešku reda `e-8` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, V, D = 2, 4, 5, 3\n",
    "\n",
    "x = np.asarray([[0, 3, 1, 2], [2, 1, 0, 3]])\n",
    "W = np.linspace(0, 1, num=V*D).reshape(V, D)\n",
    "\n",
    "out, _ = word_embedding_forward(x, W)\n",
    "expected_out = np.asarray([\n",
    " [[ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.42857143,  0.5,         0.57142857]],\n",
    " [[ 0.42857143,  0.5,         0.57142857],\n",
    "  [ 0.21428571,  0.28571429,  0.35714286],\n",
    "  [ 0.,          0.07142857,  0.14285714],\n",
    "  [ 0.64285714,  0.71428571,  0.78571429]]])\n",
    "\n",
    "print('out greška: ', rel_error(expected_out, out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding: unazad\n",
    "Implementirajte prolaz unazad za word embedding funkciju u funkciji `word_embedding_backward`. Nakon toga pokrenite sledeću ćeliju da biste provjerili vašu implementaciju. Trebalo biste vidjeti grešku reda `e-11` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, T, V, D = 50, 3, 5, 6\n",
    "x = np.random.randint(V, size=(N, T))\n",
    "W = np.random.randn(V, D)\n",
    "\n",
    "out, cache = word_embedding_forward(x, W)\n",
    "dout = np.random.randn(*out.shape)\n",
    "dW = word_embedding_backward(dout, cache)\n",
    "\n",
    "f = lambda W: word_embedding_forward(x, W)[0]\n",
    "dW_num = eval_numerical_gradient_array(f, W, dout)\n",
    "\n",
    "print('dW greška: ', rel_error(dW, dW_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Privremeni afajn sloj\n",
    "U svakom vremenskom koraku koristimo afajn funkciju da transformišemo RNN skriveni vektor u tom vremenskom koraku u scores za svaku riječ u vokabularu. Zbog toga što je veoma slično afajn sloju koji ste implementirali, mi smo vam je obezbijedili u funkcijama `temporal_affine_forward` i `temporal_affine_backward` u fajlu `funkcije/rnn_layers.py`. Pokrenite sledeće ćelije da biste provjerili vašu implementaciju. Trebali biste vidjeti grešku reda `e-9` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "N, T, D, M = 2, 3, 4, 5\n",
    "x = np.random.randn(N, T, D)\n",
    "w = np.random.randn(D, M)\n",
    "b = np.random.randn(M)\n",
    "\n",
    "out, cache = temporal_affine_forward(x, w, b)\n",
    "\n",
    "dout = np.random.randn(*out.shape)\n",
    "\n",
    "fx = lambda x: temporal_affine_forward(x, w, b)[0]\n",
    "fw = lambda w: temporal_affine_forward(x, w, b)[0]\n",
    "fb = lambda b: temporal_affine_forward(x, w, b)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dw_num = eval_numerical_gradient_array(fw, w, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "\n",
    "dx, dw, db = temporal_affine_backward(dout, cache)\n",
    "\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dw greška: ', rel_error(dw_num, dw))\n",
    "print('db greška: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Privremena Softmax funkcija cilja\n",
    "U RNN jezičkom modelu, u svakom vremenskom koraku dobijamo score za svaku riječ u vokabularu. Mi znamo pravu riječ u svakom trenutku, tako da koristimo softmax funkciju cilja da bismo izračunali funkciju cilja i gradijente u svakom vremenskom koraku. Sumiramo vrijednosti funkcije cilja tokom vremena i usrednjavamo je u minibatch.\n",
    "\n",
    "Međutim postoji začkoljica: kako radimo na minibatch-evima i različiti opisi mogu imati različite dužine, dodajemo `<NULL>` tokene na kraju svakog opisa tako da svi opisi imaju istu dužinu. Ne želimo da ti `<NULL>` tokeni utiču na gradijente i funkciju cilja, pa kao dodatak score-ovima i pravim labelama naša funkcija cilja uzima i `mask` niz koji govori o tome koji elementi utiču na funkciju cilja.\n",
    "\n",
    "Kako je ovo slično softmax funkciji cilja koju ste već implementirali, mi smo vam dali njenu implementaciju u fajlu `funkcije/rnn_layers.py` u funkciji `temporal_softmax_loss`.\n",
    "\n",
    "Pokrenite sledeću ćeliju da biste provjerili implementaciju. Trebalo bi da vidite grešku reda `e-7` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from funkcije.rnn_layers import temporal_softmax_loss\n",
    "\n",
    "N, T, V = 100, 1, 10\n",
    "\n",
    "def check_loss(N, T, V, p):\n",
    "    x = 0.001 * np.random.randn(N, T, V)\n",
    "    y = np.random.randint(V, size=(N, T))\n",
    "    mask = np.random.rand(N, T) <= p\n",
    "    print(temporal_softmax_loss(x, y, mask)[0])\n",
    "\n",
    "check_loss(100, 1, 10, 1.0)   # Treba biti oko 2.3\n",
    "check_loss(100, 10, 10, 1.0)  # Treba biti oko 23\n",
    "check_loss(5000, 10, 10, 0.1) # Treba biti oko 2.3\n",
    "\n",
    "N, T, V = 7, 8, 9\n",
    "\n",
    "x = np.random.randn(N, T, V)\n",
    "y = np.random.randint(V, size=(N, T))\n",
    "mask = (np.random.rand(N, T) > 0.5)\n",
    "\n",
    "loss, dx = temporal_softmax_loss(x, y, mask, verbose=False)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: temporal_softmax_loss(x, y, mask)[0], x, verbose=False)\n",
    "\n",
    "print('dx greška: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN za opisivanje slika\n",
    "Sada kada ste implementirali potrebne slojeve, možete ih kombinovati da napravite model za opisivanje slika. Otvorite fajl\n",
    "`funkcije/classifiers/rnn.py` i pogledajte `CaptioningRNN` klasu.\n",
    "\n",
    "Implementirajte prolaze unaprijed i unazad modela u `loss` funkciji. Za sada je potrebno da samo implementirate u slučaju gdje je `cell_type='rnn'` za vanila RNN; kasnije ćete implementirati za LSTM. Nakon toga pokrenite sledeću ćeliju i trebalo bi da vidite grešku reda `e-10` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N, D, W, H = 10, 20, 30, 40\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "V = len(word_to_idx)\n",
    "T = 13\n",
    "\n",
    "model = CaptioningRNN(word_to_idx,\n",
    "          input_dim=D,\n",
    "          wordvec_dim=W,\n",
    "          hidden_dim=H,\n",
    "          cell_type='rnn',\n",
    "          dtype=np.float64)\n",
    "\n",
    "for k, v in model.params.items():\n",
    "    model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "\n",
    "features = np.linspace(-1.5, 0.3, num=(N * D)).reshape(N, D)\n",
    "captions = (np.arange(N * T) % V).reshape(N, T)\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "expected_loss = 9.83235591003\n",
    "\n",
    "print('funkcija cilja: ', loss)\n",
    "print('očekivana vrijednost funkcije cilja: ', expected_loss)\n",
    "print('razlika: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokrenite sledeću ćeliju da biste provjerili klasu `CaptioningRNN`; trebalo biste da vidite grešku reda `e-6` ili manje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "batch_size = 2\n",
    "timesteps = 3\n",
    "input_dim = 4\n",
    "wordvec_dim = 5\n",
    "hidden_dim = 6\n",
    "word_to_idx = {'<NULL>': 0, 'cat': 2, 'dog': 3}\n",
    "vocab_size = len(word_to_idx)\n",
    "\n",
    "captions = np.random.randint(vocab_size, size=(batch_size, timesteps))\n",
    "features = np.random.randn(batch_size, input_dim)\n",
    "\n",
    "model = CaptioningRNN(word_to_idx,\n",
    "          input_dim=input_dim,\n",
    "          wordvec_dim=wordvec_dim,\n",
    "          hidden_dim=hidden_dim,\n",
    "          cell_type='rnn',\n",
    "          dtype=np.float64,\n",
    "        )\n",
    "\n",
    "loss, grads = model.loss(features, captions)\n",
    "\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(features, captions)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s relativna greška: %e' % (param_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrenirajte male podatke\n",
    "Slično `Solver` klasi koju smo koristili da treniramo klasifikacione modele u prethodnim nedeljama, ovdje ćemo koristiti klasu `CaptioningSolver` da treniramo modele opisivanja slika. Otvorite fajl `funkcije/captioning_solver.py` i prođite kroz `CaptioningSolver` klasu; trebalo bi da vam djeluje poznato.\n",
    "\n",
    "Kada se upoznate sa API-jem, pokrenite sledeću ćeliju da bi vaš model overfit-ova na malom uzorku od 100 trening primjera. Na kraju biste trebali vidjeti vrijednost funkcije cilja manju od 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "small_data = load_coco_data(max_train=50)\n",
    "\n",
    "small_rnn_model = CaptioningRNN(\n",
    "          cell_type='rnn',\n",
    "          word_to_idx=data['word_to_idx'],\n",
    "          input_dim=data['train_features'].shape[1],\n",
    "          hidden_dim=512,\n",
    "          wordvec_dim=256,\n",
    "        )\n",
    "\n",
    "small_rnn_solver = CaptioningSolver(small_rnn_model, small_data,\n",
    "           update_rule='adam',\n",
    "           num_epochs=50,\n",
    "           batch_size=25,\n",
    "           optim_config={\n",
    "             'learning_rate': 5e-3,\n",
    "           },\n",
    "           lr_decay=0.95,\n",
    "           verbose=True, print_every=10,\n",
    "         )\n",
    "\n",
    "small_rnn_solver.train()\n",
    "\n",
    "\n",
    "plt.plot(small_rnn_solver.loss_history)\n",
    "plt.xlabel('Iteracija')\n",
    "plt.ylabel('Funkcija cilja')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uzorci tokom vremena testiranja\n",
    "Za razliku od klasifikacionih modela, modeli opisivanja slika se ponašaju veoma različitom tokom vremena treniranja i testiranja. Tokom vremena treniranja imamo pristup pravim opisima, pa ubacamo prave riječi kao ulaze RNN u svakom vremenskom koraku. Tokom vremena testiranja, mi uzorkujemo iz distribucije nad rečnikom u svakom vremenskom koraku, i ubacujemo uzorak kao RNN u sledećem vremenskom koraku.\n",
    "\n",
    "U fajlu `funkcije/classifiers/rnn.py`, implementirajte `sample` metod za uzorkovanje tokom vremena testiranja. Nakon toga pokrenite sledeći uzorak iz vašeg overfitted model na trening i validacionim podacima. Uzorci na trening podacima treba da budi veoma dobri; uzorci na validacionim podacima vjerovatno neće imati smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    minibatch = sample_coco_minibatch(small_data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    sample_captions = small_rnn_model.sample(features)\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        plt.imshow(image_from_url(url))\n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
