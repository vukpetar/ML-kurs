{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvolucione mreže\n",
    "\n",
    "Nakon implementacije više vrsta slojeva koji se koriste u konvolucionim mrežama, zadatak je napraviti mrežu koja će trenirati na korpusu podataka CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from funkcije.classifiers.cnn import *\n",
    "from funkcije.data_utils import get_CIFAR10_data\n",
    "from funkcije.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from funkcije.layers import *\n",
    "from funkcije.fast_layers import *\n",
    "from funkcije.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" vraća relativnu grešku \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Učitavanje obrađenih CIFAR10 podataka.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.items():\n",
    "    print('%s: ' % k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvolucija: Naivna implementacija\n",
    "Ključna operacija konvolucionih neuralnih mreža jeste konvolucija. U `funkcije/layers.py`, implementirajte prolaz unaprijed za konvolucioni sloj unutar funkcije `conv_forward_naive`. \n",
    "\n",
    "Kao što i naslov kaže, kako se radi o naivnoj implementaciji efikasnost nije bitna. Važno je da kod funkcioniše.\n",
    "\n",
    "Testirajte svoju implementaciju koristeći sledeći kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "w_shape = (3, 3, 4, 4)\n",
    "x = np.linspace(-0.1, 0.5, num = np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num = np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num = 3)\n",
    "\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "out, _ = conv_forward_naive(x, w, b, conv_param)\n",
    "correct_out = np.array([[[[-0.08759809, -0.10987781],\n",
    "                           [-0.18387192, -0.2109216 ]],\n",
    "                          [[ 0.21027089,  0.21661097],\n",
    "                           [ 0.22847626,  0.23004637]],\n",
    "                          [[ 0.50813986,  0.54309974],\n",
    "                           [ 0.64082444,  0.67101435]]],\n",
    "                         [[[-0.98053589, -1.03143541],\n",
    "                           [-1.19128892, -1.24695841]],\n",
    "                          [[ 0.69108355,  0.66880383],\n",
    "                           [ 0.59480972,  0.56776003]],\n",
    "                          [[ 2.36270298,  2.36904306],\n",
    "                           [ 2.38090835,  2.38247847]]]])\n",
    "\n",
    "# Uporedite vaše rezultate sa našim. Greška bi trebalo da je oko e-8\n",
    "print('Testiranje conv_forward_naive')\n",
    "print('razlika: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Na stranu: Obrada slike pomoću konvolucije\n",
    "\n",
    "Kako bi provjerili implementaciju i shvatili prirodu konvolucije odnosno konvolucionog sloja, pripremili smo ulaz koji sadrži svega dvije slike sa ručno pripremljenim filterima koji vrše jednostavne operacije nad slikom, pretvaranje slike u sivoskaliranu i detekciju ivice. Sloj koji ste implementirali izvršiće ove operacije, a nakon toga ćemo vizuelizovati rezultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imread, imresize\n",
    "\n",
    "kitten, puppy = imread('kitten.jpg'), imread('puppy.jpg')\n",
    "# vršimo obradu slika kako bi imale kvadratni oblik, slika 'puppy.jpg' već ima podobne dimenzije\n",
    "d = kitten.shape[1] - kitten.shape[0]\n",
    "kitten_cropped = kitten[:, d//2:-d//2, :]\n",
    "\n",
    "img_size = 200   # sve slike koje ulaze u mrežu moraju imati konzistentne dimenzije\n",
    "x = np.zeros((2, 3, img_size, img_size))\n",
    "x[0, :, :, :] = imresize(puppy, (img_size, img_size)).transpose((2, 0, 1))\n",
    "x[1, :, :, :] = imresize(kitten_cropped, (img_size, img_size)).transpose((2, 0, 1))\n",
    "\n",
    "# Inicijalizujemo 2 filtera, dimenzija 3x3\n",
    "w = np.zeros((2, 3, 3, 3))\n",
    "\n",
    "# Prvi filtar pretvara sliku u sivoskaliranu.\n",
    "# Postavljamo vrijednosti RGB kanala filtra. Intezitet ovih vrijednosti ne treba da vas brine, odnosi se na način\n",
    "# pretvaranje slike u sivoskaliranu, a zasniva se na ljudskom vidu i načinu na koji mi uočavamo boje u prirodi.\n",
    "w[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]]\n",
    "w[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]]\n",
    "w[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]]\n",
    "\n",
    "# Drugi filtar detektuje horizontalne linije u plavom kanalu. Opet, vrijednosti nisu nasumične i dolaze iz oblasti\n",
    "# digitalne obrade slike. \n",
    "w[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]]\n",
    "\n",
    "# Nije nam potreban bias za sivoskaliranu sliku, ali jeste za detekciju ivice\n",
    "# pa dodajemo 128 jer ne želimo da dobijemo negativne vrijednosti što se može dogoditi zbog prirode filtra.\n",
    "b = np.array([0, 128])\n",
    "\n",
    "# Računamo rezultat konvolucije za svaki ulaz x upotrebom filtara w,\n",
    "# i dodajemo bias b, a rezultat smještamo u out. \n",
    "out, _ = conv_forward_naive(x, w, b, {'stride': 1, 'pad': 1})\n",
    "\n",
    "def imshow_noax(img, normalize=True):\n",
    "    \"\"\" Tiny helper to show images as uint8 and remove axis labels \"\"\"\n",
    "    if normalize:\n",
    "        img_max, img_min = np.max(img), np.min(img)\n",
    "        img = 255.0 * (img - img_min) / (img_max - img_min)\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "# Prikazujemo originalne slike i one dobijene konvolucijom.\n",
    "plt.subplot(2, 3, 1)\n",
    "imshow_noax(puppy, normalize = False)\n",
    "plt.title('Original image')\n",
    "plt.subplot(2, 3, 2)\n",
    "imshow_noax(out[0, 0])\n",
    "plt.title('Grayscale')\n",
    "plt.subplot(2, 3, 3)\n",
    "imshow_noax(out[0, 1])\n",
    "plt.title('Edges')\n",
    "plt.subplot(2, 3, 4)\n",
    "imshow_noax(kitten_cropped, normalize=  False)\n",
    "plt.subplot(2, 3, 5)\n",
    "imshow_noax(out[1, 0])\n",
    "plt.subplot(2, 3, 6)\n",
    "imshow_noax(out[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvolucija: Naivni prolaz unazad\n",
    "Implementirajte prolaz unazad za operaciju konvolucije unutar funkcije `conv_backward_naive` koja se nalazi u `funkcije/layers.py`. Ponovo ne treba voditi računa o efikasnosti.\n",
    "\n",
    "Uporedite dobijene rezultate sa numeričkim izvodom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(4, 3, 5, 5)\n",
    "w = np.random.randn(2, 3, 3, 3)\n",
    "b = np.random.randn(2,)\n",
    "dout = np.random.randn(4, 2, 5, 5)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_forward_naive(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_forward_naive(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_forward_naive(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n",
    "\n",
    "# Greška bi trebalo da je e-8 ili manja.\n",
    "print('Testiranje conv_backward_naive funkcije')\n",
    "print('dx greška: ', rel_error(dx, dx_num))\n",
    "print('dw greška: ', rel_error(dw, dw_num))\n",
    "print('db greška: ', rel_error(db, db_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Pooling: Naivna implementacija\n",
    "Implementirajte prolaz unaprijed za max-pooling operaiciju unutar funkcije `max_pool_forward_naive` koja se nalazi u `funkcije/layers.py`. Ponovo ne treba voditi računa o efikasnosti.\n",
    "\n",
    "Testirajte svoju implementaciju koristeći sledeći kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (2, 3, 4, 4)\n",
    "x = np.linspace(-0.3, 0.4, num = np.prod(x_shape)).reshape(x_shape)\n",
    "pool_param = {'pool_width': 2, 'pool_height': 2, 'stride': 2}\n",
    "\n",
    "out, _ = max_pool_forward_naive(x, pool_param)\n",
    "\n",
    "correct_out = np.array([[[[-0.26315789, -0.24842105],\n",
    "                          [-0.20421053, -0.18947368]],\n",
    "                         [[-0.14526316, -0.13052632],\n",
    "                          [-0.08631579, -0.07157895]],\n",
    "                         [[-0.02736842, -0.01263158],\n",
    "                          [ 0.03157895,  0.04631579]]],\n",
    "                        [[[ 0.09052632,  0.10526316],\n",
    "                          [ 0.14947368,  0.16421053]],\n",
    "                         [[ 0.20842105,  0.22315789],\n",
    "                          [ 0.26736842,  0.28210526]],\n",
    "                         [[ 0.32631579,  0.34105263],\n",
    "                          [ 0.38526316,  0.4       ]]]])\n",
    "\n",
    "# Uporedite vaše rezultate sa našim. Razlika bi trebalo da je reda e-8.\n",
    "print('Testiranje max_pool_forward_naive funkcije:')\n",
    "print('razlika: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-Pooling: Naivni prolaz unazad\n",
    "mplementirajte prolaz unazad za operaciju konvolucije unutar funkcije `max_pool_backward_naive` koja se nalazi u `funkcije/layers.py`. Ponovo ne treba voditi računa o efikasnosti.\n",
    "\n",
    "Uporedite dobijene rezultate sa numeričkim izvodom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(3, 2, 8, 8)\n",
    "dout = np.random.randn(3, 2, 4, 4)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: max_pool_forward_naive(x, pool_param)[0], x, dout)\n",
    "\n",
    "out, cache = max_pool_forward_naive(x, pool_param)\n",
    "dx = max_pool_backward_naive(dout, cache)\n",
    "\n",
    "# Greška bi trebalo da je e-12 ili manja \n",
    "print('Testiranje max_pool_backward_naive funkcije:')\n",
    "print('dx error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brzi slojevi\n",
    "Realizacija brzih pooling i konvolucionih slojeva nije lak zadatak. Pošto cilj ovog kursa nije optimizacija algoritama, u `funkcije/fast_layers.py` nalaze se gotove implementacije.\n",
    "\n",
    "Implementacija brze konvolucije zavisi od Cython ekstenczije, da bi je podesili iz `funkcije` morate pokrenuti sljedeće:\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```\n",
    "\n",
    "**NAPOMENA:** Brza implementacija pooling sloja će biti efikasna samo ako se pooling regije ne preklapaju. Ako ovaj uslov nije zadovoljen, brzina ove implementacije neće se puno razlikovati od one koju ste vi realizovali.\n",
    "\n",
    "Možete uporediti rezultate u brzini upotrebom sledećeg koda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relativne greške bi trebalo da su reda e-9 ili manje\n",
    "from funkcije.fast_layers import conv_forward_fast, conv_backward_fast\n",
    "from time import time\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 31, 31)\n",
    "w = np.random.randn(25, 3, 3, 3)\n",
    "b = np.random.randn(25,)\n",
    "dout = np.random.randn(100, 25, 16, 16)\n",
    "conv_param = {'stride': 2, 'pad': 1}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = conv_forward_naive(x, w, b, conv_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = conv_forward_fast(x, w, b, conv_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testiranje conv_forward_fast:')\n",
    "print('Naivni pristup: %fs' % (t1 - t0))\n",
    "print('Brzi pristup: %fs' % (t2 - t1))\n",
    "print('Ubrzanje: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Razlika: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive, dw_naive, db_naive = conv_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast, dw_fast, db_fast = conv_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTestiranje conv_backward_fast:')\n",
    "print('Naivni pristup: %fs' % (t1 - t0))\n",
    "print('Brzi pristup: %fs' % (t2 - t1))\n",
    "print('Ubrzanje: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx razlika: ', rel_error(dx_naive, dx_fast))\n",
    "print('dw razlika: ', rel_error(dw_naive, dw_fast))\n",
    "print('db razlika: ', rel_error(db_naive, db_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relativne greške bi trebalo da su blizu 0.0\n",
    "from funkcije.fast_layers import max_pool_forward_fast, max_pool_backward_fast\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(100, 3, 32, 32)\n",
    "dout = np.random.randn(100, 3, 16, 16)\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "t0 = time()\n",
    "out_naive, cache_naive = max_pool_forward_naive(x, pool_param)\n",
    "t1 = time()\n",
    "out_fast, cache_fast = max_pool_forward_fast(x, pool_param)\n",
    "t2 = time()\n",
    "\n",
    "print('Testiranje pool_forward_fast:')\n",
    "print('Naivni pristup: %fs' % (t1 - t0))\n",
    "print('Brzi pristup: %fs' % (t2 - t1))\n",
    "print('Ubrzanje: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('Razlika: ', rel_error(out_naive, out_fast))\n",
    "\n",
    "t0 = time()\n",
    "dx_naive = max_pool_backward_naive(dout, cache_naive)\n",
    "t1 = time()\n",
    "dx_fast = max_pool_backward_fast(dout, cache_fast)\n",
    "t2 = time()\n",
    "\n",
    "print('\\nTestiranje pool_backward_fast:')\n",
    "print('Naivni pristup: %fs' % (t1 - t0))\n",
    "print('Brzi pristup: %fs' % (t2 - t1))\n",
    "print('Ubrzanje: %fx' % ((t1 - t0) / (t2 - t1)))\n",
    "print('dx razlika: ', rel_error(dx_naive, dx_fast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konvolucioni \"sendvič\" slojevi\n",
    "Prethodno smo uveli koncept \"sendvič\" slojeva koji kombinuju nekoliko operacija koje predstavljaju šablon. U `funkcije/layer_utils.py` se mogu naći sendvič slojevi sa par različitih šablona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funkcije.layer_utils import conv_relu_pool_forward, conv_relu_pool_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_pool_forward(x, w, b, conv_param, pool_param)\n",
    "dx, dw, db = conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_pool_forward(x, w, b, conv_param, pool_param)[0], b, dout)\n",
    "\n",
    "# Relativne greške bi trebalo da su oko e-8 ili manje\n",
    "print('Testiranje conv_relu_pool')\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dw greška: ', rel_error(dw_num, dw))\n",
    "print('db greška: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funkcije.layer_utils import conv_relu_forward, conv_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 8, 8)\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "\n",
    "out, cache = conv_relu_forward(x, w, b, conv_param)\n",
    "dx, dw, db = conv_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_forward(x, w, b, conv_param)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: conv_relu_forward(x, w, b, conv_param)[0], b, dout)\n",
    "\n",
    "# Relativne greške bi trebalo da su oko e-8 ili manje\n",
    "print('Testiranje conv_relu:')\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dw greška: ', rel_error(dw_num, dw))\n",
    "print('db greška: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troslojna konvoluciona mreža (ConvNet)\n",
    "Nakon što ste implementirali sve potrebne slojeve, možemo ih spojiti u jednu cjelinu, troslojnu mrežu.\n",
    "\n",
    "Otvorite `funkcije/classifiers/cnn.py` i završite implementaciju `ThreeLayerConvNet` klase. Ne zaboravite da možete koristi u implementaciji brze/sendvič slojeve koje ste već dobili.\n",
    "\n",
    "Iskoristite sledeći kod da provjerite realizaciju:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provjera loss-a\n",
    "Nakon što konstruišete mrežu, prva stvar koju treba provjeriti jeste loss funkcija. Kada koristimo softmax loss, očekujemo da za nasumične vrijednosti težina (bez regularizacije) vrijednost loss-a bude `log(C)` za `C` klasa. Kada dodamo regularizaciju ova vrijednost bi trebalo da se poveća"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet()\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size = N)\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Inicijalni loss (bez regularizacije): ', loss)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print('Inicijalni loss (sa regularizacijom): ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provjera gradijenta\n",
    "Ukoliko loss djeluje dobro, sledeće što treba uraditi jeste upotrebom numeričkog gradijenta provjeriti realizaciju prolaska unazad. Napomena: svi rezultati greške do e-2 bi trebalo da su dobri. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "np.random.seed(231)\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size = num_inputs)\n",
    "\n",
    "model = ThreeLayerConvNet(num_filters = 3, filter_size = 3,\n",
    "                          input_dim = input_dim, hidden_dim = 7,\n",
    "                          dtype = np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose = False, h = 1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s maksimalna relativna greška: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitovanje na malom broju ulaznih podataka\n",
    "Kao još jedna od provjera jeste upotreba malog broja ulaznih podataka i velikog broja epoha. Ovim ćemo dobiti ogromnu preciznost na trening podacima, a značajno manju na validacionim podacima. Time dokazujemo da je mreža u stanju da uči."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "model = ThreeLayerConvNet(weight_scale = 1e-2)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs = 15, batch_size = 50,\n",
    "                update_rule = 'adam',\n",
    "                optim_config = {\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose = True, print_every = 1)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crtanje loss-a, trening preciznost i preciznosti na validacionim podacima će jasno pokazati da je došlo do overfita:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteracija')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['trening', 'validacija'], loc = 'upper left')\n",
    "plt.xlabel('epoha')\n",
    "plt.ylabel('preciznost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treniranje mreže\n",
    "Treniranjem konvolucione mreže u samo jednoj epohi bi trebalo da da preciznost veću od 40%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = ThreeLayerConvNet(weight_scale=0.001, hidden_dim=500, reg=0.001)\n",
    "\n",
    "solver = Solver(model, data,\n",
    "                num_epochs = 1, batch_size = 50,\n",
    "                update_rule = 'adam',\n",
    "                optim_config = {\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose = True, print_every = 20)\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizuelizacija filtera\n",
    "Moguće je vizuelizovati prvi sloj filtera konvolucione mreže upotrebom sledećeg koda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funkcije.vis_utils import visualize_grid\n",
    "\n",
    "grid = visualize_grid(model.params['W1'].transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prostorna Batch Normalizacija\n",
    "Kao što je već demonstrirano na nastavi, a i u originalnom radu [3], batch normalizacija (BN) se može koristiti za konvolucione mreže, ali se mora malo modifikovati. Ova modifikacija naziva se \"prostornom batch normalizacijom\". \n",
    "\n",
    "U slučaju FC slojeva, BN dobija ulazne podatke dimenzija `(N, D)`, a izlaz je takođe dimenzija `(N, D)` dok se normalizacija vrši po dimenziji `N`. U slučaju konvolucionog sloja, BN na svom ulazu dobija podatke dimenzija `(N, C, H, W)`. Izlaz je takođe dimenzija `(N, C, H, W)` gdje `N` dimenzija predstavlja veličinu mini batch-a, a `(H, W)` predstavlja prostorne dimenzije feature mape.\n",
    "\n",
    "Ukoliko je feature mapa dobijena upotrebom konvolucije, tada očekujemo da će statistika svih feature kanala bili relativno konzistentna između različitih slika, ali i različitih lokacija na istoj slici. Zbog toga prostorna batch normalizacija računa srednju vrijednost i varijansu za svake `C` feature kanale tako što računa statistiku ne samo po dimenziji `N` već i po dimenzijama `H` i `W`.\n",
    "\n",
    "[3] [Sergey Ioffe and Christian Szegedy, \"Batch Normalization: Accelerating Deep Network Training by Reducing\n",
    "Internal Covariate Shift\", ICML 2015.](https://arxiv.org/abs/1502.03167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prostorna BN: forward\n",
    "\n",
    "U `funkcije/layers.py`, implementirajte prolaz unaprijed za prostornu BN unutar funkcije `spatial_batchnorm_forward`. Testirajte implementaciju pokretanjem sledećeg koda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "# Provjerite prolaz unaprijed tokom treniranja tako što ćete provjeriti srednju\n",
    "# vrijednost i varijansu parametara kako prije tako i poslije prostorne BN\n",
    "\n",
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "\n",
    "print('Prije prostorne BN:')\n",
    "print('  Dimenzije: ', x.shape)\n",
    "print('  Srednje vr.: ', x.mean(axis = (0, 2, 3)))\n",
    "print('  Standardna dev.: ', x.std(axis = (0, 2, 3)))\n",
    "\n",
    "# Srednje vrijednosti bi trebalo da su blizu nula, a standardne devijacije oko jedan\n",
    "gamma, beta = np.ones(C), np.zeros(C)\n",
    "bn_param = {'mode': 'train'}\n",
    "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "print('Nakon prostorne BN:')\n",
    "print('  Dimenzije: ', out.shape)\n",
    "print('  Srednje vr.: ', out.mean(axis = (0, 2, 3)))\n",
    "print('  Standardna dev.: ', out.std(axis = (0, 2, 3)))\n",
    "\n",
    "# Srednje vrijednosti bi trebalo da su blizu beta, a standardne devijacije oko gamma\n",
    "gamma, beta = np.asarray([3, 4, 5]), np.asarray([6, 7, 8])\n",
    "out, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "print('Nakon prostorne BN (netrivijalne beta i gamma):')\n",
    "print('  Dimenzije: ', out.shape)\n",
    "print('  Srednje vr.: ', out.mean(axis = (0, 2, 3)))\n",
    "print('  Standardna dev.: ', out.std(axis = (0, 2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "# Sada ćemo provjeriti rad u režimu testiranja tako što ćemo proći\n",
    "# kroz režim treniranja više puta kako bismo \"zagrijali\" srednje vrijednosti\n",
    "# a onda provjerili rezultate\n",
    "\n",
    "N, C, H, W = 10, 4, 11, 12\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "gamma = np.ones(C)\n",
    "beta = np.zeros(C)\n",
    "for t in range(50):\n",
    "    x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "    spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "bn_param['mode'] = 'test'\n",
    "x = 2.3 * np.random.randn(N, C, H, W) + 13\n",
    "a_norm, _ = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "\n",
    "# Srednje vrijednosti bi trebalo da su blizu nula, a standardne devijacije oko jedan, ali sa određenim šumom\n",
    "print('Nakon prostorne BN (režim testiranja):')\n",
    "print('  Srednje vr.: ', a_norm.mean(axis = (0, 2, 3)))\n",
    "print('  Standardna dev.: ', a_norm.std(axis = (0, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prostorna BN: backward\n",
    "U `funkcije/layers.py`, implementirajte prolaz unazad za prostornu BN unutar funkcije `spatial_batchnorm_backward`. Testirajte svoju implementaciju poređenjem sa numeričkim gradijentom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, C, H, W = 2, 3, 4, 5\n",
    "x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "gamma = np.random.randn(C)\n",
    "beta = np.random.randn(C)\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "bn_param = {'mode': 'train'}\n",
    "fx = lambda x: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fg = lambda a: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "fb = lambda b: spatial_batchnorm_forward(x, gamma, beta, bn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "#Greška bi trebalo da je reda 1e-12~1e-06\n",
    "_, cache = spatial_batchnorm_forward(x, gamma, beta, bn_param)\n",
    "dx, dgamma, dbeta = spatial_batchnorm_backward(dout, cache)\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dgamma greška: ', rel_error(da_num, dgamma))\n",
    "print('dbeta greška: ', rel_error(db_num, dbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupna normalizacija\n",
    "\n",
    "Ranije je pominjana sloj normalizacija (Layer Normalization) kao alternativna tehnika koja anulira neke od mana batch normalizacije. Kao što su autori [4] zaključili, LN ne daje dobre rezultate kao BN u konvolucionim neuralnim mrežama:\n",
    "\n",
    "> Kod FC slojeva, svi skriveni neuroni teže da imaju isti doprinos pri računanju konačne predikcije, iz tog razloga centriranje i skaliranje ulaza u neuron radi očekivano dobro. Međutim, ista pretpostavka ne važi kod konvolucionih neuralnih mreža. Kako dubina konvolucione neuralne mreže raste tako raste i broj neurona čije receptivno polje pada blizu okvira slike i rijetko su \"upaljeni\" (množe vrijednost različitu od nule), i zbog toga imaju veoma različitu statistiku od ostatka neurona u istom sloju.\n",
    "\n",
    "Autori [5] predlažu neku vrstu prelaznog rješenja. Za razliku od LN gdje se normalizuju svi featuri po jednom ulazu, ideja ovih autora je da se jedna feature mapa podijeli u G podgrupa na kojim će se vršiti normalizacija.  \n",
    "\n",
    "![Comparison of normalization techniques discussed so far](normalization.png)\n",
    "<center>**Vizuelno poređenje diskutovanih metoda (slika iz [5])**</center>\n",
    "\n",
    "Vaš zadatak je da sada implementirate grupnu normalizaciju. Imajte na umu da je BN metoda stara četiri godine i već ustaljena, dok je GN metoda razvijena prije nešto više od godinu dana!\n",
    "\n",
    "[4] [Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer Normalization.\" stat 1050 (2016): 21.](https://arxiv.org/pdf/1607.06450.pdf)\n",
    "\n",
    "\n",
    "[5] [Wu, Yuxin, and Kaiming He. \"Group Normalization.\" arXiv preprint arXiv:1803.08494 (2018).](https://arxiv.org/abs/1803.08494)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupna normalizacija: forward\n",
    "\n",
    "U `funkcije/layers.py`, implementirajte prolaz unaprijed za grupnu normalizaciju unutar funkcije `spatial_groupnorm_forward`. Testirajte svoju implementaciju upotrebom sledećeg koda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "\n",
    "# Provjerite prolaz unaprijed tokom treniranja tako što ćete provjeriti srednju\n",
    "# vrijednost i varijansu parametara kako prije tako i poslije prostorne GN\n",
    "\n",
    "N, C, H, W = 2, 6, 4, 5\n",
    "G = 2\n",
    "x = 4 * np.random.randn(N, C, H, W) + 10\n",
    "x_g = x.reshape((N*G,-1))\n",
    "\n",
    "print('Prije prostorne GN:')\n",
    "print('  Dimenzije: ', x.shape)\n",
    "print('  Srednje vr.: ', x_g.mean(axis = 1))\n",
    "print('  Standardna dev.: ', x_g.std(axis = 1))\n",
    "\n",
    "# Srednje vrijednosti bi trebalo da su blizu nula, a standardne devijacije oko jedan\n",
    "gamma, beta = np.ones((1,C,1,1)), np.zeros((1,C,1,1))\n",
    "bn_param = {'mode': 'train'}\n",
    "\n",
    "out, _ = spatial_groupnorm_forward(x, gamma, beta, G, bn_param)\n",
    "out_g = out.reshape((N*G,-1))\n",
    "print('Nakon prostorne GN:')\n",
    "print('  Dimenzije: ', out.shape)\n",
    "print('  Srednje vr.: ', out_g.mean(axis = 1))\n",
    "print('  Standardna dev.: ', out_g.std(axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupna normalizacija: backward\n",
    "\n",
    "U `funkcije/layers.py`, implementirajte prolaz unazad za grupnu normalizaciju unutar funkcije `spatial_groupnorm_backward`. Testirajte svoju implementaciju poređenjem sa numeričkim gradijentom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "N, C, H, W = 2, 6, 4, 5\n",
    "G = 2\n",
    "x = 5 * np.random.randn(N, C, H, W) + 12\n",
    "gamma = np.random.randn(1,C,1,1)\n",
    "beta = np.random.randn(1,C,1,1)\n",
    "dout = np.random.randn(N, C, H, W)\n",
    "\n",
    "gn_param = {}\n",
    "fx = lambda x: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "fg = lambda a: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "fb = lambda b: spatial_groupnorm_forward(x, gamma, beta, G, gn_param)[0]\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "da_num = eval_numerical_gradient_array(fg, gamma, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, beta, dout)\n",
    "\n",
    "_, cache = spatial_groupnorm_forward(x, gamma, beta, G, gn_param)\n",
    "dx, dgamma, dbeta = spatial_groupnorm_backward(dout, cache)\n",
    "\n",
    "#Greška bi trebalo da je reda 1e-12~1e-07\n",
    "print('dx greška: ', rel_error(dx_num, dx))\n",
    "print('dgamma greška: ', rel_error(da_num, dgamma))\n",
    "print('dbeta greška: ', rel_error(db_num, dbeta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
