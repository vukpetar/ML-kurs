{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preuzimanje korpusa podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tarfile, urllib.request\n",
    "if(not os.path.isdir(\"funkcije/datasets/cifar-10-batches-py\")):\n",
    "    urllib.request.urlretrieve(\"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\", \"cifar-10-python.tar.gz\")\n",
    "\n",
    "    tar = tarfile.open(\"cifar-10-python.tar.gz\", \"r:gz\")\n",
    "    tar.extractall(\"funkcije/datasets/\")\n",
    "    tar.close()\n",
    "    os.remove(\"cifar-10-python.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacija Neuralne Mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom primjeru će biti demonstrirana neuralna mreža sa FC slojem čiji zadatak je klasifikacija i njeno testiranje na CIFAR-10 dataset-u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" Vraća relativnu grešku. \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koristiće se klasa TwoLayerNet da bi se predstavile instance mreže. Parametri mreže su smješteni u varijable instance self.params gdje ključevi su stringovi koji predstavljaju imena parametara i vrijednosti su numpy nizovi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(object):\n",
    "    \"\"\"\n",
    "    Dvoslojna FC neuralna mreža. Mreža ima ulaznu dimenziju N, skriveni sloj dimenzije H i \n",
    "    vrši klasifikaciju u C klasa. Mreža se trenira sa softmax loss funkcijom i L2 regularizacijom\n",
    "    na matrice težina. Mreža koristi ReLU aktivacionu funkciju nakon prvog FC sloja.\n",
    "    Drugim riječima, mreža ima sledeću arhitekturu:\n",
    "    ulaz - FC sloj - ReLU - FC sloj - softmax\n",
    "    Izlazi iz drugog FC sloja su scores za svaku klasu.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, std=1e-4):\n",
    "        \"\"\"\n",
    "        Inicijalizacija modela. Težine su inicijalizovane na male, slučajne vrijednosti\n",
    "        i biasi su inicijalizovani na 0. Težine i biasi se smještaju u varijable self.params,\n",
    "        koji je rečnik sa sledećim ključevima:\n",
    "        W1: Težine prvog sloja; dimenzije (D, H)\n",
    "        b1: Bias prvog sloja; dimenzije (H,)\n",
    "        W2: Težine drugog sloja; dimenzije (H, C)\n",
    "        b2: Bias drugog sloja; dimenzije (C,)\n",
    "        Ulazi:\n",
    "        - input_size: Dimenzija D ulaznih podataka.\n",
    "        - hidden_size: Broj neurona H u skrivenom sloju.\n",
    "        - output_size: Broj klasa C.\n",
    "        \"\"\"\n",
    "        # TODO: Inicijalizacija parametara mreže.\n",
    "        pass\n",
    "\n",
    "    def loss(self, X, y=None, reg=0.0):\n",
    "        \"\"\"\n",
    "        Računanje funkcije cilja i gradijenata za dvoslojnu FC neuralnu mrežu.\n",
    "        Ulazi:\n",
    "        - X: Ulazni podaci dimenzija (N, D). Svaki X[i] je trening uzorak.\n",
    "        - y: Vektor trening labela. y[i] je labela za X[i], i svaki y[i] je\n",
    "          integer u opsegu 0 <= y[i] < C. Ovaj parametar je opcionalan; ako se ne proslijedi\n",
    "          onda se vraćaju samo scores, a  ako se proslijedi onda se vraća funkcija cilja i gradijenti.\n",
    "        - reg: Snaga regularizacije.\n",
    "        Rezultat:\n",
    "        Ako je y None, vraća se matrica scores dimenzija (N, C) gdje scores[i, c] je\n",
    "        score za klasu c ulaza X[i].\n",
    "        Ako y nije None, onda se vraća tuple:\n",
    "        - loss: Loss (data loss and regularization loss) za ovaj batch trening uzoraka.\n",
    "        - grads: Rečnik koji mapira imena parametara u gradijente tih parametara uzimajući \n",
    "        u obzir funkciju cilja; ima iste ključeve kao self.params.\n",
    "        \"\"\"\n",
    "        # Raspakovati varijable iz params rečnika.\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        N, D = X.shape\n",
    "\n",
    "        # Računanje forward pass.\n",
    "        scores = None\n",
    "        #############################################################################\n",
    "        # TODO: Izvršiti forward pass, računanje skora klase za ulaze.              \n",
    "        # Smještanje rezultata u skorove varijable, koji bi trebao da bude niz      \n",
    "        # dimenzija (N, C).                                                         \n",
    "        #############################################################################\n",
    "\n",
    "\n",
    "        if y is None:\n",
    "            return scores\n",
    "\n",
    "        loss = None\n",
    "        #############################################################################\n",
    "        # TODO: Završavanje forward pass, i računanje funkcije cilja. Ovdje treba   \n",
    "        # uključiti i podatke o funkciji cilja i L2 regularizaciji za W1 i W2.      \n",
    "        # Upisati rezultat u varijablu loss koja treba da bude skalar.              \n",
    "        # Koristiti softmax classifier loss.         \n",
    "        #############################################################################\n",
    "\n",
    "        \n",
    "        \n",
    "        grads = {}\n",
    "        #############################################################################\n",
    "        # TODO: Izračunati backward pass, računanjem izvoda težina i biasa. Upisati \n",
    "        # rezultat u rečnik grads. Na primjer, u grads['W1'] treba upisati gradijent        \n",
    "        # W1 i treba da bude matrica istih dimenzija kao W1.\n",
    "        #############################################################################\n",
    "\n",
    "\n",
    "        return loss, grads\n",
    "\n",
    "    def train(self, X, y, X_val, y_val,\n",
    "              learning_rate=1e-3, learning_rate_decay=0.95,\n",
    "              reg=5e-6, num_iters=100,\n",
    "              batch_size=200, verbose=False):\n",
    "        \"\"\"\n",
    "        Treniranje neuralne mreže koristeći stohastički algoritam opadajućeg gradijenta.\n",
    "        Ulazi: \n",
    "        - X: Numpy niz dimenzija (N, D) koji predstavlja trening podatke.\n",
    "        - y: Numpy niz dimenzija (N,) koji predstavlja labele trening podataka; y[i] = c označava da\n",
    "          X[i] ima labelu c, gdje je 0 <= c < C.\n",
    "        - X_val: Numpy niz dimenzija (N_val, D) koji predstavlja validacione podatke.\n",
    "        - y_val: Numpy niz dimenzija (N_val,) koji predstavlja labele validacionih podataka.\n",
    "        - learning_rate: Skalar koji predstavlja stopu učenja za optimizaciju.\n",
    "        - learning_rate_decay: Skalar koji predstavlja faktor koji se koristi za opadanje stope učenja nakon svake epohe.\n",
    "        - reg: Skalar koji predstavlja snagu regularizacije.\n",
    "        - num_iters: Broj iteracija.\n",
    "        - batch_size: Broj trening uzoraka koji se koriste po koraku.\n",
    "        - verbose: boolean; Ako je True štampati napredak tokom optimizacije.\n",
    "        \"\"\"\n",
    "        num_train = X.shape[0]\n",
    "        iterations_per_epoch = max(num_train / batch_size, 1)\n",
    "\n",
    "        loss_history = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "\n",
    "        for it in range(num_iters):\n",
    "\n",
    "            #########################################################################\n",
    "            # TODO: Kreirati slučajno minibatch trening podataka i labela, smještajući ih \n",
    "            # u X_batch i y_batch respektivno.                            \n",
    "            #########################################################################\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            #########################################################################\n",
    "            # TODO: Koristiti gradijente iz rečnika grads da bi se ažurirali parametri mreže         \n",
    "            # koristeći algoritam opadajućeg gradijenta. \n",
    "            #########################################################################\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "            if verbose and it % 100 == 0:\n",
    "                print('iteration %d / %d: loss %f' % (it, num_iters, loss))\n",
    "\n",
    "     \n",
    "            if it % iterations_per_epoch == 0:\n",
    "                train_acc = (self.predict(X_batch) == y_batch).mean()\n",
    "                val_acc = (self.predict(X_val) == y_val).mean()\n",
    "                train_acc_history.append(train_acc)\n",
    "                val_acc_history.append(val_acc)\n",
    "                \n",
    "                learning_rate *= learning_rate_decay\n",
    "\n",
    "        return {\n",
    "          'loss_history': loss_history,\n",
    "          'train_acc_history': train_acc_history,\n",
    "          'val_acc_history': val_acc_history,\n",
    "        }\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Koristiti trenirane težine dvoslojne mreže da predvidi labele za podatke.\n",
    "        Za svaki podatak predviđa se skor za svaku od C klasa, i svakom podatku\n",
    "        se dodjeljuje klasa sa najveći skorom.\n",
    "        Ulazi:\n",
    "        - X: Numpy niz dimenzija (N, D) koji predstavlja N D-dimenzionalnih podataka za klasifikaciju.\n",
    "        Rezultat:\n",
    "        - y_pred: Numpy niz dimenzija (N,) koji predstavlja predviđene labele za svaki element niza X.\n",
    "          Za svako i, y_pred[i] = c znači da se za X[i] predviđa klasa c, gdje je 0 <= c < C.\n",
    "        \"\"\"\n",
    "        y_pred = None\n",
    "\n",
    "        ###########################################################################\n",
    "        # TODO: Implementirati funkciju.\n",
    "        ###########################################################################\n",
    "        \n",
    "        pass\n",
    "       \n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicijalizacija toy data i toy model koji će se koristiti za razvijanje modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: računanje skora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "print('Razlika između skora mreže i stvarnog skora:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: računanje funkcije cilja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "print('Razlika između fukncije cilja mreže i tačne funkcije cilja:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_numerical_gradient(f, x, verbose=True, h=0.00001):\n",
    "    \"\"\"\n",
    "    Naivna implementacija numeričkog gradijenta f-a u x\n",
    "    - f treba da bude funkcija koja koristi jedan argument\n",
    "    - x je tačka (numpy niz) za evaluaciju gradijenta\n",
    "    \"\"\"\n",
    "\n",
    "    fx = f(x) \n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        ix = it.multi_index\n",
    "        oldval = x[ix]\n",
    "        x[ix] = oldval + h \n",
    "        fxph = f(x)\n",
    "        x[ix] = oldval - h\n",
    "        fxmh = f(x)\n",
    "        x[ix] = oldval \n",
    "\n",
    "        grad[ix] = (fxph - fxmh) / (2 * h) \n",
    "        if verbose:\n",
    "            print(ix, grad[ix])\n",
    "        it.iternext() \n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s maksimalna relativna greška: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treniranje mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za treniranje mreže koristiće se stohastički algoritam opadajućeg gradijenta (SGD). Treniranje je testirano na toy podacima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Konačni trening loss: ', stats['loss_history'][-1])\n",
    "\n",
    "\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteracija')\n",
    "plt.ylabel('trening loss')\n",
    "plt.title('Trening Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Učitavanje podataka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon testiranja na toy podacima, koristiće se CIFAR-10 dataset i vršiti treniranje mreže i njihova klasifikacija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Učitavanje CIFAR-10 dataset-a sa diska i izvršavanje pripreme podataka \n",
    "    za dvoslojnu neuralnu mrežu za klasifikaciju. \n",
    "    \"\"\"\n",
    "\n",
    "    cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "    \n",
    "    try:\n",
    "        del X_train, y_train\n",
    "        del X_test, y_test\n",
    "        print('Brisanje prethodno učitanih podataka.')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Dimenzije trening podataka: ', X_train.shape)\n",
    "print('Dimenzije labela trening podataka: ', y_train.shape)\n",
    "print('Dimenzije validacionih podataka: ', X_val.shape)\n",
    "print('Dimenzije labela validacionih podataka: ', y_val.shape)\n",
    "print('Dimenzije testnih podataka: ', X_test.shape)\n",
    "print('Dimenzije labela testnih podataka: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treniranje mreže"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za treniranje mreže će se koristiti SGD. Stopa učenja će biti podešena sa eksponencijalnom stopom učenja u toku optimizacije; nakon svake epohe, stopa učenja će biti pomnožena sa stopom opadanja (decay rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Tačnost validacije: ', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa korištenim parametrima se neće dobiti visoka tačnost.\n",
    "\n",
    "Za debagovanje prvo će se nacrtati grafici funkcije cilja i tačnosti na trening i validacionom setu tokom optimizacije.\n",
    "\n",
    "Druga strategija je grafičko prikazivanje težina koje su naučene u prvom sloju mrežu. U većini neuralnih mreža treniranih na slikama, težine prvog sloja obično imaju neku uočljivu strukturu kada se vizuelizuju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteracija')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Tačnost klasifikacije history')\n",
    "plt.xlabel('Epoha')\n",
    "plt.ylabel('Tačnost klasifikacije')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, ceil\n",
    "\n",
    "def visualize_grid(Xs, ubound=255.0, padding=1):\n",
    "    \"\"\"\n",
    "    Predimenzioniranje 4D tenzora slike u mrežu laku za vizuelitaciju.\n",
    "\n",
    "    Ulazi:\n",
    "    - Xs: Podaci dimenzija (N, H, W, C)\n",
    "    - ubound: Izlazna mreža će imati vrijednosti skalirane u opsegu [0, ubound]\n",
    "    - padding: Broj praznih piksela između elemenata mreže\n",
    "    \"\"\"\n",
    "    (N, H, W, C) = Xs.shape\n",
    "    grid_size = int(ceil(sqrt(N)))\n",
    "    grid_height = H * grid_size + padding * (grid_size - 1)\n",
    "    grid_width = W * grid_size + padding * (grid_size - 1)\n",
    "    grid = np.zeros((grid_height, grid_width, C))\n",
    "    next_idx = 0\n",
    "    y0, y1 = 0, H\n",
    "    for y in range(grid_size):\n",
    "        x0, x1 = 0, W\n",
    "        for x in range(grid_size):\n",
    "            if next_idx < N:\n",
    "                img = Xs[next_idx]\n",
    "                low, high = np.min(img), np.max(img)\n",
    "                grid[y0:y1, x0:x1] = ubound * (img - low) / (high - low)\n",
    "                next_idx += 1\n",
    "            x0 += W + padding\n",
    "            x1 += W + padding\n",
    "        y0 += H + padding\n",
    "        y1 += H + padding\n",
    "    return grid\n",
    "\n",
    "def vis_grid(Xs):\n",
    "    \"\"\" Vizuelizovanje mreže slike \"\"\"\n",
    "    (N, H, W, C) = Xs.shape\n",
    "    A = int(ceil(sqrt(N)))\n",
    "    G = np.ones((A*H+A, A*W+A, C), Xs.dtype)\n",
    "    G *= np.min(Xs)\n",
    "    n = 0\n",
    "    for y in range(A):\n",
    "        for x in range(A):\n",
    "            if n < N:\n",
    "                G[y*H+y:(y+1)*H+y, x*W+x:(x+1)*W+x, :] = Xs[n,:,:,:]\n",
    "                n += 1\n",
    "    maxg = G.max()\n",
    "    ming = G.min()\n",
    "    G = (G - ming)/(maxg-ming)\n",
    "    return G\n",
    "\n",
    "def vis_nn(rows):\n",
    "    \"\"\" Vizuelizovanje niza nizova slika \"\"\"\n",
    "    N = len(rows)\n",
    "    D = len(rows[0])\n",
    "    H,W,C = rows[0][0].shape\n",
    "    Xs = rows[0][0]\n",
    "    G = np.ones((N*H+N, D*W+D, C), Xs.dtype)\n",
    "    for y in range(N):\n",
    "        for x in range(D):\n",
    "            G[y*H+y:(y+1)*H+y, x*W+x:(x+1)*W+x, :] = rows[y][x]\n",
    "    maxg = G.max()\n",
    "    ming = G.min()\n",
    "    G = (G - ming)/(maxg-ming)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podešavanje hiperparametara radi postizanja najbolje tačnosti klasifikacije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.linspace(1.5e-4, 1e-3, 5)\n",
    "regularization_strengths = np.linspace(.25, .50, 5)\n",
    "hidden_size_ =  [75, 100, 125, 150]\n",
    "results = {}\n",
    "best_net = None \n",
    "best_val = -1\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "best_stats = None\n",
    "#################################################################################\n",
    "# Podešavanje hiperparametara koristeći validacioni set. Smjestiti najbolje \n",
    "# istrenirani model u best_net.                                                                                    \n",
    "#################################################################################\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        for hz in hidden_size_:\n",
    "            net_ = TwoLayerNet(input_size, hz, num_classes)\n",
    "            stat = net_.train(X_train, y_train, X_val, y_val,\n",
    "                num_iters=1000, batch_size=200,\n",
    "                learning_rate=lr, learning_rate_decay=0.95,\n",
    "                reg=reg, verbose=False)\n",
    "            y_train_pred = net_.predict(X_train)\n",
    "            train_acc = np.mean(y_train == y_train_pred)\n",
    "            y_val_pred = net_.predict(X_val)\n",
    "            val_acc = np.mean(y_val == y_val_pred)\n",
    "            results[(lr, reg, hz)] = (train_acc,val_acc)\n",
    "            if best_val<val_acc:\n",
    "                best_val = val_acc\n",
    "                best_net = net_\n",
    "                best_stats = stat\n",
    "                print('lr %e reg %e hz %e Tačnost trening seta: %f Tačnost validacionog seta: %f' % (\n",
    "                lr, reg, hz, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(best_stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteracija')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(best_stats['train_acc_history'], label='train')\n",
    "plt.plot(best_stats['val_acc_history'], label='val')\n",
    "plt.title('Tačnost klasifikacije history')\n",
    "plt.xlabel('Epoha')\n",
    "plt.ylabel('Tačnost klasifikacije')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluacija najboljeg modela na test setu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Tačnost testa: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
